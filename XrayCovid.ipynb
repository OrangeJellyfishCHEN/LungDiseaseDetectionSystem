{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup packages and GPUs"
      ],
      "metadata": {
        "id": "gre5NVPlbubb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -U torch -q\n",
        "# !pip install -U torchvision -q\n",
        "# !pip install -U Pillow -q"
      ],
      "metadata": {
        "id": "w274_xPYb4Zq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MTbnlUxE_HJq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29c7001e-bf7e-4597-8bf0-0e9d34473ff9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import segmentation_models_pytorch as smp\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import shutil\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import torchvision.transforms.functional as TF\n",
        "import os, warnings\n",
        "import random\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import glob\n",
        "import pandas as pd\n",
        "import time\n",
        "import copy\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Data"
      ],
      "metadata": {
        "id": "spkzIYrj9Dy7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the original database into the training, testing and validation sets.\n",
        "- Build the required directory structure first."
      ],
      "metadata": {
        "id": "dF4VvSJTU4vV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "root_dir = '/content/drive/MyDrive/Projects/datasets/COVID-19_Radiography_Dataset'\n",
        "splitted_dir = os.path.join(root_dir, \"Splitted_database\")\n",
        "os.makedirs(splitted_dir, exist_ok=True)\n",
        "source_dir = '/content/drive/MyDrive/Projects/datasets/COVID-19_Radiography_Dataset'\n",
        "target_dir = '/content/drive/MyDrive/Projects/datasets/COVID-19_Radiography_Dataset/Splitted_database'\n",
        "os.makedirs(target_dir, exist_ok=True)\n",
        "train_dir = os.path.join(target_dir, 'train')\n",
        "val_dir = os.path.join(target_dir, 'val')\n",
        "test_dir = os.path.join(target_dir, 'test')"
      ],
      "metadata": {
        "id": "q8fuEiqpMdfg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b663922e-80b5-4054-9276-dfd40c473ae5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function for splitting the database. Here is the folder structure after splitting:\n",
        "* **Splitted_database/**\n",
        "  * **train/** - [70% of data]\n",
        "    * **COVID/**\n",
        "      * **images/** - [70% of COVID images]\n",
        "      * **masks/** - [70% of COVID masks]\n",
        "    * **Viral_Pneumonia/**\n",
        "      * **images/** - [70% of Viral_Pneumonia images]\n",
        "      * **masks/** - [70% of Viral_Pneumonia masks]\n",
        "    * **Normal/**\n",
        "      * **images/** - [70% of Normal images]\n",
        "      * **masks/** - [70% of Normal masks]\n",
        "  * **val/** - [15% of data]\n",
        "    * **COVID/**\n",
        "      * **images/** - [15% of COVID images]\n",
        "      * **masks/** - [15% of COVID masks]\n",
        "    * **Viral_Pneumonia/**\n",
        "      * **images/** - [15% of Viral_Pneumonia images]\n",
        "      * **masks/** - [15% of Viral_Pneumonia masks]\n",
        "    * **Normal/**\n",
        "      * **images/** - [15% of Normal images]\n",
        "      * **masks/** - [15% of Normal masks]\n",
        "  * **test/** - [15% of data]\n",
        "    * **COVID/**\n",
        "      * **images/** - [15% of COVID images]\n",
        "      * **masks/** - [15% of COVID masks]\n",
        "    * **Viral_Pneumonia/**\n",
        "      * **images/** - [15% of Viral_Pneumonia images]\n",
        "      * **masks/** - [15% of Viral_Pneumonia masks]\n",
        "    * **Normal/**\n",
        "      * **images/** - [15% of Normal images]\n",
        "      * **masks/** - [15% of Normal masks]"
      ],
      "metadata": {
        "id": "7su-f-Ddge0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_dataset(test_ratio=0.15, val_ratio=0.15, seed=42):\n",
        "    \"\"\"\n",
        "    Split the dataset into training, validation and testing sets while maintaining the folder structure.\n",
        "\n",
        "    Args:\n",
        "        source_dir (str): Path to the source dataset directory\n",
        "        target_dir (str): Path to the target directory where train/val/test will be created\n",
        "        test_ratio (float): Ratio of test data (default: 0.15)\n",
        "        val_ratio (float): Ratio of validation data (default: 0.15)\n",
        "        seed (int): Random seed for reproducibility\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    # Create the folder structure\n",
        "    for class_name in ['COVID', 'Viral_Pneumonia', 'Normal']:\n",
        "        os.makedirs(os.path.join(train_dir, class_name, 'images'), exist_ok=True)\n",
        "        os.makedirs(os.path.join(train_dir, class_name, 'masks'), exist_ok=True)\n",
        "        os.makedirs(os.path.join(val_dir, class_name, 'images'), exist_ok=True)\n",
        "        os.makedirs(os.path.join(val_dir, class_name, 'masks'), exist_ok=True)\n",
        "        os.makedirs(os.path.join(test_dir, class_name, 'images'), exist_ok=True)\n",
        "        os.makedirs(os.path.join(test_dir, class_name, 'masks'), exist_ok=True)\n",
        "    for class_name in ['COVID', 'Viral_Pneumonia', 'Normal']:\n",
        "        print(f\"Processing {class_name} class...\")\n",
        "        img_dir = os.path.join(source_dir, class_name, 'images')\n",
        "        mask_dir = os.path.join(source_dir, class_name, 'masks')\n",
        "\n",
        "        image_files = sorted([f for f in os.listdir(img_dir) if not f.startswith('.') and \"(\" not in f])\n",
        "        mask_files = sorted([f for f in os.listdir(mask_dir) if not f.startswith('.') and \"(\" not in f])\n",
        "        # Check if the numbers of image and mask are equal\n",
        "        if len(image_files) != len(mask_files):\n",
        "            print(f\"Warning: Number of images ({len(image_files)}) doesn't match number of masks ({len(mask_files)}) for {class_name}\")\n",
        "        # Paired image with its corresponding masks\n",
        "        paired_files = []\n",
        "        for img_file in image_files:\n",
        "            mask_basename = os.path.splitext(img_file)[0]\n",
        "            matching_masks = [m for m in mask_files if os.path.splitext(m)[0] == mask_basename]\n",
        "\n",
        "            if matching_masks:\n",
        "                paired_files.append((img_file, matching_masks[0]))\n",
        "            else:\n",
        "                print(f\"Warning: No matching mask found for image {img_file}\")\n",
        "        random.shuffle(paired_files)\n",
        "        total_count = len(paired_files)\n",
        "        test_size = int(total_count * test_ratio)\n",
        "        val_size = int(total_count * val_ratio)\n",
        "        train_size = total_count - test_size - val_size\n",
        "        test_pairs = paired_files[:test_size]\n",
        "        val_pairs = paired_files[test_size:test_size+val_size]\n",
        "        train_pairs = paired_files[test_size+val_size:]\n",
        "        print(f\"  {class_name}: Total: {total_count}, Train: {len(train_pairs)}, Val: {len(val_pairs)}, Test: {len(test_pairs)}\")\n",
        "        # Load images into new directory in splitted directory\n",
        "        for img_file, mask_file in train_pairs:\n",
        "            src_img = os.path.join(source_dir, class_name, 'images', img_file)\n",
        "            dst_img = os.path.join(train_dir, class_name, 'images', img_file)\n",
        "            shutil.copy2(src_img, dst_img)\n",
        "            src_mask = os.path.join(source_dir, class_name, 'masks', mask_file)\n",
        "            dst_mask = os.path.join(train_dir, class_name, 'masks', mask_file)\n",
        "            shutil.copy2(src_mask, dst_mask)\n",
        "        for img_file, mask_file in val_pairs:\n",
        "            src_img = os.path.join(source_dir, class_name, 'images', img_file)\n",
        "            dst_img = os.path.join(val_dir, class_name, 'images', img_file)\n",
        "            shutil.copy2(src_img, dst_img)\n",
        "            src_mask = os.path.join(source_dir, class_name, 'masks', mask_file)\n",
        "            dst_mask = os.path.join(val_dir, class_name, 'masks', mask_file)\n",
        "            shutil.copy2(src_mask, dst_mask)\n",
        "        for img_file, mask_file in test_pairs:\n",
        "            src_img = os.path.join(source_dir, class_name, 'images', img_file)\n",
        "            dst_img = os.path.join(test_dir, class_name, 'images', img_file)\n",
        "            shutil.copy2(src_img, dst_img)\n",
        "            src_mask = os.path.join(source_dir, class_name, 'masks', mask_file)\n",
        "            dst_mask = os.path.join(test_dir, class_name, 'masks', mask_file)\n",
        "            shutil.copy2(src_mask, dst_mask)\n",
        "    print(\"Dataset splitting complete!\")\n",
        "    # Print dataset structure\n",
        "    print(\"\\nDataset Structure:\")\n",
        "    print(\"-\" * 60)\n",
        "    print(\"Class       | Train Images | Valid Images  | Test Images | Total\")\n",
        "    print(\"-\" * 60)\n",
        "    total_train = 0\n",
        "    total_val = 0\n",
        "    total_test = 0\n",
        "    for class_name in ['COVID', 'Viral_Pneumonia', 'Normal']:\n",
        "        train_count = len(os.listdir(os.path.join(train_dir, class_name, 'images')))\n",
        "        val_count = len(os.listdir(os.path.join(val_dir, class_name, 'images')))\n",
        "        test_count = len(os.listdir(os.path.join(test_dir, class_name, 'images')))\n",
        "        total = train_count + val_count + test_count\n",
        "        print(f\"{class_name:<12}| {train_count:<13}| {val_count:<12}| {test_count:<12}| {total}\")\n",
        "        total_train += train_count\n",
        "        total_val += val_count\n",
        "        total_test += test_count\n",
        "    print(\"-\" * 60)\n",
        "    print(f\"Total       | {total_train:<13}| {total_val:<12}| {total_test:<12}| {total_train + total_val + total_test}\")\n",
        "    print(\"-\" * 60)"
      ],
      "metadata": {
        "id": "6X08LXKFrsyk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Except the first time or the dataset not splitted as expect, don't run this line:\n",
        "# split_dataset(test_ratio=0.15, val_ratio=0.15)"
      ],
      "metadata": {
        "id": "-zkxay09UViW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check if the database is splitted as expected data proportion(Here is test/valdation/train = 15%/15%/70%), pairred masks and structure.   \n",
        "This step is to check the last step is finished or not (cuz take too long time last step)."
      ],
      "metadata": {
        "id": "nFNRE138twZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_files(directory):\n",
        "    \"\"\"Count the number of files in a directory.\"\"\"\n",
        "    if not os.path.exists(directory):\n",
        "        return 0\n",
        "    return len([f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))])\n",
        "\n",
        "\n",
        "def validate_split(base_path):\n",
        "    # if new split method (as 10/10/80) should change here:\n",
        "    expected_counts = {\n",
        "        'COVID': {'total': 3616, 'train': 2532, 'val': 542, 'test': 542},\n",
        "        'Viral_Pneumonia': {'total': 1345, 'train': 943, 'val': 201, 'test': 201},\n",
        "        'Normal': {'total': 10192, 'train': 7136, 'val': 1528, 'test': 1528}\n",
        "    }\n",
        "    actual_counts = {\n",
        "        'COVID': {'train_images': 0, 'train_masks': 0,\n",
        "                  'val_images': 0, 'val_masks': 0,\n",
        "                  'test_images': 0, 'test_masks': 0},\n",
        "        'Viral_Pneumonia': {'train_images': 0, 'train_masks': 0,\n",
        "                           'val_images': 0, 'val_masks': 0,\n",
        "                           'test_images': 0, 'test_masks': 0},\n",
        "        'Normal': {'train_images': 0, 'train_masks': 0,\n",
        "                  'val_images': 0, 'val_masks': 0,\n",
        "                  'test_images': 0, 'test_masks': 0}\n",
        "    }\n",
        "    for split in ['train', 'val', 'test']:\n",
        "        split_path = os.path.join(base_path, split)\n",
        "        if not os.path.exists(split_path):\n",
        "            print(f\"Warning: Split directory '{split_path}' does not exist.\")\n",
        "            continue\n",
        "\n",
        "        for class_name in ['COVID', 'Viral_Pneumonia', 'Normal']:\n",
        "            class_path = os.path.join(split_path, class_name)\n",
        "            if not os.path.exists(class_path):\n",
        "                print(f\"Warning: Class directory '{class_path}' does not exist.\")\n",
        "                continue\n",
        "\n",
        "            images_path = os.path.join(class_path, 'images')\n",
        "            masks_path = os.path.join(class_path, 'masks')\n",
        "\n",
        "            if os.path.exists(images_path):\n",
        "                actual_counts[class_name][f'{split}_images'] = count_files(images_path)\n",
        "            else:\n",
        "                print(f\"Warning: Images directory '{images_path}' does not exist.\")\n",
        "\n",
        "            if os.path.exists(masks_path):\n",
        "                actual_counts[class_name][f'{split}_masks'] = count_files(masks_path)\n",
        "            else:\n",
        "                print(f\"Warning: Masks directory '{masks_path}' does not exist.\")\n",
        "    results = []\n",
        "\n",
        "    for class_name, counts in actual_counts.items():\n",
        "        train_images = counts['train_images']\n",
        "        val_images = counts['val_images']\n",
        "        test_images = counts['test_images']\n",
        "        total_images = train_images + val_images + test_images\n",
        "\n",
        "        train_masks = counts['train_masks']\n",
        "        val_masks = counts['val_masks']\n",
        "        test_masks = counts['test_masks']\n",
        "        total_masks = train_masks + val_masks + test_masks\n",
        "\n",
        "        expected = expected_counts[class_name]\n",
        "        images_match = (\n",
        "            train_images == expected['train'] and\n",
        "            val_images == expected['val'] and\n",
        "            test_images == expected['test'] and\n",
        "            total_images == expected['total']\n",
        "        )\n",
        "        masks_match_images = (\n",
        "            train_masks == train_images and\n",
        "            val_masks == val_images and\n",
        "            test_masks == test_images and\n",
        "            total_masks == total_images\n",
        "        )\n",
        "        train_pct = round(train_images / total_images * 100, 1) if total_images > 0 else 0\n",
        "        val_pct = round(val_images / total_images * 100, 1) if total_images > 0 else 0\n",
        "        test_pct = round(test_images / total_images * 100, 1) if total_images > 0 else 0\n",
        "        results.append({\n",
        "            'Class': class_name,\n",
        "            'Train Images': train_images,\n",
        "            'Val Images': val_images,\n",
        "            'Test Images': test_images,\n",
        "            'Total Images': total_images,\n",
        "            'Train %': train_pct,\n",
        "            'Val %': val_pct,\n",
        "            'Test %': test_pct,\n",
        "            'Train Masks': train_masks,\n",
        "            'Val Masks': val_masks,\n",
        "            'Test Masks': test_masks,\n",
        "            'Total Masks': total_masks,\n",
        "            'Expected Train': expected['train'],\n",
        "            'Expected Val': expected['val'],\n",
        "            'Expected Test': expected['test'],\n",
        "            'Expected Total': expected['total'],\n",
        "            'Images Match Expected': images_match,\n",
        "            'Masks Match Images': masks_match_images\n",
        "        })\n",
        "    df = pd.DataFrame(results)\n",
        "    print(\"\\n=== Dataset Split Validation Results ===\\n\")\n",
        "    print(df[['Class', 'Train Images', 'Train %', 'Val Images', 'Val %', 'Test Images', 'Test %', 'Total Images',\n",
        "              'Images Match Expected', 'Masks Match Images']])\n",
        "    mismatches = df[~df['Images Match Expected'] | ~df['Masks Match Images']]\n",
        "    if not mismatches.empty:\n",
        "        print(\"\\n=== Detailed Analysis for Mismatches ===\\n\")\n",
        "        for _, row in mismatches.iterrows():\n",
        "            class_name = row['Class']\n",
        "            print(f\"Class: {class_name}\")\n",
        "\n",
        "            if not row['Images Match Expected']:\n",
        "                print(\"  Image count mismatch:\")\n",
        "                print(f\"    Train: {row['Train Images']} (Expected: {row['Expected Train']})\")\n",
        "                print(f\"    Val: {row['Val Images']} (Expected: {row['Expected Val']})\")\n",
        "                print(f\"    Test: {row['Test Images']} (Expected: {row['Expected Test']})\")\n",
        "                print(f\"    Total: {row['Total Images']} (Expected: {row['Expected Total']})\")\n",
        "\n",
        "            if not row['Masks Match Images']:\n",
        "                print(\"  Mask-Image count mismatch:\")\n",
        "                print(f\"    Train: {row['Train Masks']} masks vs {row['Train Images']} images\")\n",
        "                print(f\"    Val: {row['Val Masks']} masks vs {row['Val Images']} images\")\n",
        "                print(f\"    Test: {row['Test Masks']} masks vs {row['Test Images']} images\")\n",
        "                print(f\"    Total: {row['Total Masks']} masks vs {row['Total Images']} images\")\n",
        "            print()\n",
        "    else:\n",
        "        print(\"\\nAll classes have correct splits and matching masks/images counts! ✓\")\n",
        "    overall_correct_split = True\n",
        "    for _, row in df.iterrows():\n",
        "        # if new split method (as 10/10/80) should change here also:\n",
        "        if abs(row['Train %'] - 70) > 1 or abs(row['Val %'] - 15) > 1 or abs(row['Test %'] - 15) > 1:\n",
        "            overall_correct_split = False\n",
        "    if overall_correct_split:\n",
        "        print(\"\\nSplit Correctly!\")\n",
        "    else:\n",
        "        print(\"\\nWarning: The distribution doesn't match the expected distribution!!!\")\n",
        "    return df"
      ],
      "metadata": {
        "id": "o5p4M8mPZ-dB",
        "collapsed": true
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    results = validate_split(splitted_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfHFIjopr-9z",
        "outputId": "0c37add4-48a2-41c8-8386-6054dcc15d18"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Dataset Split Validation Results ===\n",
            "\n",
            "             Class  Train Images  Train %  Val Images  Val %  Test Images  \\\n",
            "0            COVID          2532     70.0         542   15.0          542   \n",
            "1  Viral_Pneumonia           943     70.1         201   14.9          201   \n",
            "2           Normal          7136     70.0        1528   15.0         1528   \n",
            "\n",
            "   Test %  Total Images  Images Match Expected  Masks Match Images  \n",
            "0    15.0          3616                   True                True  \n",
            "1    14.9          1345                   True                True  \n",
            "2    15.0         10192                   True                True  \n",
            "\n",
            "All classes have correct splits and matching masks/images counts! ✓\n",
            "\n",
            "Split Correctly!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "load data and apply data pre-processing steps on it."
      ],
      "metadata": {
        "id": "Poj0SEkvLC5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "class_types = ['train', 'val', 'test']\n",
        "def data_pre_processing(img_path, mask_path):\n",
        "    try:\n",
        "        # Normalization Config from ImageNet based models\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean, std)\n",
        "        ])\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        mask = Image.open(mask_path).convert('L')\n",
        "        img_tensor = transform(img)\n",
        "        mask = mask.resize((224, 224), Image.NEAREST)\n",
        "        mask_temsor = TF.to_tensor(mask)\n",
        "        mask_temsor = (mask_temsor > 0.5).float()\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {img_path} and {mask_path}: {e}\")\n",
        "        return None, None\n",
        "    return img_tensor, mask_temsor"
      ],
      "metadata": {
        "id": "aP4a5tiKYlkg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_map = {'COVID': 0, 'Viral_Pneumonia': 1, 'Normal': 2}\n",
        "dataloaders = {}\n",
        "# only shuffle the training set\n",
        "for class_l in class_types:\n",
        "    images = []\n",
        "    masks = []\n",
        "    labels = []\n",
        "    cur_class_path = os.path.join(target_dir, class_l)\n",
        "    if not os.path.exists(cur_class_path):\n",
        "        print(f\"Warning! {cur_class_path} does not exists!\")\n",
        "        break\n",
        "    else:\n",
        "        print(cur_class_path)\n",
        "        for class_name in class_map.keys():\n",
        "            class_dir = os.path.join(cur_class_path, class_name)\n",
        "        if not os.path.exists(class_dir):\n",
        "            print(f\"Warning! {class_dir} does not exists!\")\n",
        "            break\n",
        "        else:\n",
        "            image_dir = os.path.join(class_dir, 'images')\n",
        "            mask_dir = os.path.join(class_dir, 'masks')\n",
        "            if not os.path.exists(image_dir) or not os.path.exists(mask_dir):\n",
        "                print(f\"Warning! {image_dir} or {mask_dir} does not exists!\")\n",
        "                break\n",
        "            else:\n",
        "                image_files = glob.glob(os.path.join(image_dir, '*'))\n",
        "                for img_path in image_files:\n",
        "                    # get the correspounding mask file\n",
        "                    # the mask and the correspounding original image has the same name\n",
        "                    img_filename = os.path.basename(img_path)\n",
        "                    mask_path = os.path.join(mask_dir, img_filename)\n",
        "                    if os.path.exists(mask_path):\n",
        "                        img_tensor, mask_tensor = data_pre_processing(img_path, mask_path)\n",
        "                        if img_tensor is not None or mask_tensor is not None:\n",
        "                            images.append(img_tensor)\n",
        "                            masks.append(mask_tensor)\n",
        "                            labels.append(class_map[class_name])\n",
        "                if images:\n",
        "                    images = torch.stack(images)\n",
        "                    masks = torch.stack(masks)\n",
        "                    labels = torch.tensor(labels)\n",
        "                    print(f\"{class_l} loaded {len(images)} samples\")\n",
        "                    dataset = TensorDataset(images, masks, labels)\n",
        "                    shuffle = (class_l == 'train')\n",
        "                    dataloaders[class_l] = DataLoader(dataset, batch_size=16, shuffle=shuffle)\n",
        "                    print(dataloaders)\n",
        "                else:\n",
        "                    print(f\"No images found in {class_l}, please check code + data folder again\")\n",
        "                    break\n",
        ""
      ],
      "metadata": {
        "id": "T5xAdWiYLHFF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "4f9a7305-ca92-498b-8800-8e1e8b35b21b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Projects/datasets/COVID-19_Radiography_Dataset/Splitted_database/train\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-0fdb8b6839c4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m                     \u001b[0mmask_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                         \u001b[0mimg_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_pre_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mimg_tensor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmask_tensor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                             \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-96da2bb80079>\u001b[0m in \u001b[0;36mdata_pre_processing\u001b[0;34m(img_path, mask_path)\u001b[0m\n\u001b[1;32m     11\u001b[0m         ])\n\u001b[1;32m     12\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'L'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mimg_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEAREST\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3514\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3516\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3518\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show a batch of the sample."
      ],
      "metadata": {
        "id": "80Qc3P6-OKRc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataloaders)\n",
        "images, masks, labels = next(iter(dataloaders['train']))\n",
        "mean = torch.tensor(mean).view(1, 3, 1, 1)\n",
        "std = torch.tensor(std).view(1, 3, 1, 1)\n",
        "images_display = (images * std) + mean\n",
        "images_display = images_display.clamp(0, 1)\n",
        "fig, axes = plt.subplots(4, 3, figsize=(12, 10))\n",
        "# only display first four\n",
        "for i in range(4):\n",
        "    img = images_display[i].permute(1, 2, 0).cpu().numpy()\n",
        "    axes[i, 0].imshow(img)\n",
        "    axes[i, 0].set_title(f'Image {i+1}, Class: {class_types[labels[i]]}')\n",
        "    axes[i, 0].axis('off')\n",
        "    axes[i, 1].imshow(masks[i].cpu().numpy(), cmap='gray')\n",
        "    axes[i, 1].set_title(f'Mask {i+1}')\n",
        "    axes[i, 1].axis('off')\n",
        "    overlay = img.copy()\n",
        "    mask_np = masks[i][0].numpy()\n",
        "    # show mask as a red overlay layer\n",
        "    for c in range(3):\n",
        "        channel_overlay = overlay[:, :, c].copy()\n",
        "        if c == 0:\n",
        "            channel_overlay[mask_np > 0.5] = 1.0\n",
        "        else:\n",
        "            channel_overlay[mask_np > 0.5] = 0.5\n",
        "        overlay[:, :, c] = channel_overlay\n",
        "    alpha = 0.3\n",
        "    blended = (1-alpha) * img + alpha * overlay\n",
        "    axes[i, 2].imshow(blended)\n",
        "    axes[i, 2].set_title(f'Blended {i+1}')\n",
        "    axes[i, 2].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "_Z1JxiHY2P8G",
        "outputId": "1dff0aef-f210-40e7-f21e-e93be91d59bd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'train'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-f3c18ac795d6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimages_display\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'train'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create The Model\n",
        "## Create the Unet"
      ],
      "metadata": {
        "id": "6FIXZlor2ikC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unet_model = smp.Unet(\n",
        "    encoder_name=\"resnet18\",\n",
        "    encoder_weights=\"imagenet\",\n",
        "    in_channels=3,\n",
        "    classes=3,\n",
        "    activation=\"sigmoid\"\n",
        ")"
      ],
      "metadata": {
        "id": "8gdacSqlOQST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the ResNet-18"
      ],
      "metadata": {
        "id": "AC0o3tFi3rVp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# this pretrain is on imagenet by pytorch\n",
        "resnet18_model = models.resnet18(pretrained=True)\n",
        "num_ftrs = resnet18_model.fc.in_features\n",
        "resnet18_model = nn.Linear(num_ftrs, 3)\n",
        "return resnet_18"
      ],
      "metadata": {
        "id": "Q3b49EbH3tnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combined two models together"
      ],
      "metadata": {
        "id": "ygEyDiTq6gUQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss function Combination."
      ],
      "metadata": {
        "id": "XcMSNxSXSXI0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loss weight should be [seg_weight:cls_weight] to define which event is more important\n",
        "def loss_function(seg_pred, cls_pred, seg_true, cls_true, loss_weight):\n",
        "    seg_criterion = nn.BCELoss()\n",
        "    cls_criterion = nn.CrossEntropyLoss()\n",
        "    seg_loss = seg_criterion(seg_pred, seg_true)\n",
        "    cls_loss = cls_criterion(cls_pred, cls_true)\n",
        "    total_loss = seg_loss * loss_weight[0] + cls_loss * loss_weight[1]\n",
        "    return total_loss, seg_loss, cls_loss"
      ],
      "metadata": {
        "id": "TLFG--e4SWV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def combine_model(x):\n",
        "    original_conv = resnet18_model.conv1\n",
        "    resnet18_model.conv1 = nn.Conv2d(\n",
        "        4,\n",
        "        original_conv.out_channels,\n",
        "        kernel_size=original_conv.kernel_size,\n",
        "        stride=original_conv.stride\n",
        "        padding=original_conv.padding,\n",
        "        bias=original_conv.bias\n",
        "    )\n",
        "    with torch.no_grad():\n",
        "        resnet18_model.conv1.weight[:, :3] = original_conv.weight\n",
        "    # foward propagation function\n",
        "    def foward_pf(x):\n",
        "        mask = unet_model(x)\n",
        "        x_combine = torch.cat((images, mask), dim=1)\n",
        "        classification = resnet18_model(x_combine)\n",
        "        return mask, classification\n",
        "    return foward_pf, (unet_model, resnet18_model)"
      ],
      "metadata": {
        "id": "g66GzPXM6f_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the Model"
      ],
      "metadata": {
        "id": "GgB864sTYUAd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# scheduler: to adjust the study rate\n",
        "# patience: for early stopping\n",
        "def train_model(foward_pf, models, dataloaders, optimizer, loss_weight, scheduler=None, num_epochs=25, patience=5):\n",
        "    # preparation stage\n",
        "    seg_model, classfy_model = models\n",
        "    seg_model = seg_model.to(device)\n",
        "    classify_model = classify_model.to(device)\n",
        "    best_seg_state = copy.deepcopy(seg_model.state_dict())\n",
        "    best_cls_state = copy.deepcopy(classify_model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    best_epoch = 0\n",
        "    history = {\n",
        "        'train_loss': [], 'val_loss': [],\n",
        "        'train_seg_loss': [], 'val_seg_loss': [],\n",
        "        'train_cls_loss': [], 'val_cls_loss': [],\n",
        "        'train_acc': [], 'val_acc': []\n",
        "    }\n",
        "    counter = 0\n",
        "    # training stage\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "        print('-' * 10)\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                seg_model.train()\n",
        "                classify_model.train()\n",
        "            else:\n",
        "                seg_model.eval()\n",
        "                classify_model.eval()\n",
        "            running_loss = 0.0\n",
        "            running_seg_loss = 0.0\n",
        "            running_cls_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            for inputs, masks, labels in dataloaders[phase]:\n",
        ""
      ],
      "metadata": {
        "id": "1xZR79y-YmBM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}