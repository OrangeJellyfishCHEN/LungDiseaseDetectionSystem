{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup packages and GPUs\n",
        "Uncomment to install following packages in this cell if you needed."
      ],
      "metadata": {
        "id": "gre5NVPlbubb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -U torch -q\n",
        "# !pip install -U torchvision -q\n",
        "# !pip install -U segmentation-models-pytorch -q\n",
        "# !pip install -U matplotlib -q\n",
        "# !pip install -U Pillow -q\n",
        "# !pip install numpy==1.23.5 -q\n",
        "# !pip install -U pandas -q\n",
        "# !pip install -U scikit-learn -q\n",
        "# !pip install -U seaborn -q"
      ],
      "metadata": {
        "id": "w274_xPYb4Zq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MTbnlUxE_HJq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f41ea892-3a9a-48b0-dea5-2f6c0870788d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import segmentation_models_pytorch as smp\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import shutil\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import torchvision.transforms.functional as TF\n",
        "import os, warnings\n",
        "import random\n",
        "from pathlib import Path\n",
        "import glob\n",
        "import pandas as pd\n",
        "import time\n",
        "import copy\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import sys\n",
        "\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Data"
      ],
      "metadata": {
        "id": "spkzIYrj9Dy7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the original database into the training, testing and validation sets.\n",
        "- Build the required directory structure first."
      ],
      "metadata": {
        "id": "dF4VvSJTU4vV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "root_dir = '/content/drive/MyDrive/Projects/datasets/COVID-19_Radiography_Dataset'\n",
        "splitted_dir = os.path.join(root_dir, \"Splitted_database\")\n",
        "os.makedirs(splitted_dir, exist_ok=True)\n",
        "source_dir = '/content/drive/MyDrive/Projects/datasets/COVID-19_Radiography_Dataset'\n",
        "target_dir = '/content/drive/MyDrive/Projects/datasets/COVID-19_Radiography_Dataset/Splitted_database'\n",
        "os.makedirs(target_dir, exist_ok=True)\n",
        "train_dir = os.path.join(target_dir, 'train')\n",
        "val_dir = os.path.join(target_dir, 'val')\n",
        "test_dir = os.path.join(target_dir, 'test')\n",
        "class_names = ['COVID', 'Viral_Pneumonia', 'Normal']"
      ],
      "metadata": {
        "id": "q8fuEiqpMdfg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e47a46f-f62a-4924-ea7a-c76c60a3cf19"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function for splitting the database. Here is the folder structure after splitting:\n",
        "* **Splitted_database/**\n",
        "  * **train/** - [70% of data]\n",
        "    * **COVID/**\n",
        "      * **images/** - [70% of COVID images]\n",
        "      * **masks/** - [70% of COVID masks]\n",
        "    * **Viral_Pneumonia/**\n",
        "      * **images/** - [70% of Viral_Pneumonia images]\n",
        "      * **masks/** - [70% of Viral_Pneumonia masks]\n",
        "    * **Normal/**\n",
        "      * **images/** - [70% of Normal images]\n",
        "      * **masks/** - [70% of Normal masks]\n",
        "  * **val/** - [15% of data]\n",
        "    * **COVID/**\n",
        "      * **images/** - [15% of COVID images]\n",
        "      * **masks/** - [15% of COVID masks]\n",
        "    * **Viral_Pneumonia/**\n",
        "      * **images/** - [15% of Viral_Pneumonia images]\n",
        "      * **masks/** - [15% of Viral_Pneumonia masks]\n",
        "    * **Normal/**\n",
        "      * **images/** - [15% of Normal images]\n",
        "      * **masks/** - [15% of Normal masks]\n",
        "  * **test/** - [15% of data]\n",
        "    * **COVID/**\n",
        "      * **images/** - [15% of COVID images]\n",
        "      * **masks/** - [15% of COVID masks]\n",
        "    * **Viral_Pneumonia/**\n",
        "      * **images/** - [15% of Viral_Pneumonia images]\n",
        "      * **masks/** - [15% of Viral_Pneumonia masks]\n",
        "    * **Normal/**\n",
        "      * **images/** - [15% of Normal images]\n",
        "      * **masks/** - [15% of Normal masks]"
      ],
      "metadata": {
        "id": "7su-f-Ddge0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_dataset(test_ratio=0.15, val_ratio=0.15, seed=42):\n",
        "    \"\"\"\n",
        "    Split the dataset into training, validation and testing sets while maintaining the folder structure.\n",
        "\n",
        "    Args:\n",
        "        source_dir (str): Path to the source dataset directory\n",
        "        target_dir (str): Path to the target directory where train/val/test will be created\n",
        "        test_ratio (float): Ratio of test data (default: 0.15)\n",
        "        val_ratio (float): Ratio of validation data (default: 0.15)\n",
        "        seed (int): Random seed for reproducibility\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    # Create the folder structure\n",
        "    for class_name in class_names:\n",
        "        os.makedirs(os.path.join(train_dir, class_name, 'images'), exist_ok=True)\n",
        "        os.makedirs(os.path.join(train_dir, class_name, 'masks'), exist_ok=True)\n",
        "        os.makedirs(os.path.join(val_dir, class_name, 'images'), exist_ok=True)\n",
        "        os.makedirs(os.path.join(val_dir, class_name, 'masks'), exist_ok=True)\n",
        "        os.makedirs(os.path.join(test_dir, class_name, 'images'), exist_ok=True)\n",
        "        os.makedirs(os.path.join(test_dir, class_name, 'masks'), exist_ok=True)\n",
        "    for class_name in class_names:\n",
        "        print(f\"Processing {class_name} class...\")\n",
        "        img_dir = os.path.join(source_dir, class_name, 'images')\n",
        "        mask_dir = os.path.join(source_dir, class_name, 'masks')\n",
        "\n",
        "        image_files = sorted([f for f in os.listdir(img_dir) if not f.startswith('.') and \"(\" not in f])\n",
        "        mask_files = sorted([f for f in os.listdir(mask_dir) if not f.startswith('.') and \"(\" not in f])\n",
        "        # Check if the numbers of image and mask are equal\n",
        "        if len(image_files) != len(mask_files):\n",
        "            print(f\"Warning: Number of images ({len(image_files)}) doesn't match number of masks ({len(mask_files)}) for {class_name}\")\n",
        "        # Paired image with its corresponding masks\n",
        "        paired_files = []\n",
        "        for img_file in image_files:\n",
        "            mask_basename = os.path.splitext(img_file)[0]\n",
        "            matching_masks = [m for m in mask_files if os.path.splitext(m)[0] == mask_basename]\n",
        "\n",
        "            if matching_masks:\n",
        "                paired_files.append((img_file, matching_masks[0]))\n",
        "            else:\n",
        "                print(f\"Warning: No matching mask found for image {img_file}\")\n",
        "        random.shuffle(paired_files)\n",
        "        total_count = len(paired_files)\n",
        "        test_size = int(total_count * test_ratio)\n",
        "        val_size = int(total_count * val_ratio)\n",
        "        train_size = total_count - test_size - val_size\n",
        "        test_pairs = paired_files[:test_size]\n",
        "        val_pairs = paired_files[test_size:test_size+val_size]\n",
        "        train_pairs = paired_files[test_size+val_size:]\n",
        "        print(f\"  {class_name}: Total: {total_count}, Train: {len(train_pairs)}, Val: {len(val_pairs)}, Test: {len(test_pairs)}\")\n",
        "        # Load images into new directory in splitted directory\n",
        "        for img_file, mask_file in train_pairs:\n",
        "            src_img = os.path.join(source_dir, class_name, 'images', img_file)\n",
        "            dst_img = os.path.join(train_dir, class_name, 'images', img_file)\n",
        "            shutil.copy2(src_img, dst_img)\n",
        "            src_mask = os.path.join(source_dir, class_name, 'masks', mask_file)\n",
        "            dst_mask = os.path.join(train_dir, class_name, 'masks', mask_file)\n",
        "            shutil.copy2(src_mask, dst_mask)\n",
        "        for img_file, mask_file in val_pairs:\n",
        "            src_img = os.path.join(source_dir, class_name, 'images', img_file)\n",
        "            dst_img = os.path.join(val_dir, class_name, 'images', img_file)\n",
        "            shutil.copy2(src_img, dst_img)\n",
        "            src_mask = os.path.join(source_dir, class_name, 'masks', mask_file)\n",
        "            dst_mask = os.path.join(val_dir, class_name, 'masks', mask_file)\n",
        "            shutil.copy2(src_mask, dst_mask)\n",
        "        for img_file, mask_file in test_pairs:\n",
        "            src_img = os.path.join(source_dir, class_name, 'images', img_file)\n",
        "            dst_img = os.path.join(test_dir, class_name, 'images', img_file)\n",
        "            shutil.copy2(src_img, dst_img)\n",
        "            src_mask = os.path.join(source_dir, class_name, 'masks', mask_file)\n",
        "            dst_mask = os.path.join(test_dir, class_name, 'masks', mask_file)\n",
        "            shutil.copy2(src_mask, dst_mask)\n",
        "    print(\"Dataset splitting complete!\")\n",
        "    # Print dataset structure\n",
        "    print(\"\\nDataset Structure:\")\n",
        "    print(\"-\" * 60)\n",
        "    print(\"Class       | Train Images | Valid Images  | Test Images | Total\")\n",
        "    print(\"-\" * 60)\n",
        "    total_train = 0\n",
        "    total_val = 0\n",
        "    total_test = 0\n",
        "    for class_name in class_names:\n",
        "        train_count = len(os.listdir(os.path.join(train_dir, class_name, 'images')))\n",
        "        val_count = len(os.listdir(os.path.join(val_dir, class_name, 'images')))\n",
        "        test_count = len(os.listdir(os.path.join(test_dir, class_name, 'images')))\n",
        "        total = train_count + val_count + test_count\n",
        "        print(f\"{class_name:<12}| {train_count:<13}| {val_count:<12}| {test_count:<12}| {total}\")\n",
        "        total_train += train_count\n",
        "        total_val += val_count\n",
        "        total_test += test_count\n",
        "    print(\"-\" * 60)\n",
        "    print(f\"Total       | {total_train:<13}| {total_val:<12}| {total_test:<12}| {total_train + total_val + total_test}\")\n",
        "    print(\"-\" * 60)"
      ],
      "metadata": {
        "id": "6X08LXKFrsyk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Except the first time or the dataset not splitted as expect, don't run this line:\n",
        "# split_dataset(test_ratio=0.15, val_ratio=0.15)"
      ],
      "metadata": {
        "id": "-zkxay09UViW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check if the database is splitted as expected data proportion(Here is test/valdation/train = 15%/15%/70%), pairred masks and structure.   \n",
        "This step is to check the last step is finished or not (cuz take too long time last step)."
      ],
      "metadata": {
        "id": "nFNRE138twZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_files(directory):\n",
        "    \"\"\"Count the number of files in a directory.\"\"\"\n",
        "    if not os.path.exists(directory):\n",
        "        return 0\n",
        "    return len([f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))])\n",
        "\n",
        "\n",
        "def validate_split(base_path):\n",
        "    # if new split method (as 10/10/80) should change here:\n",
        "    expected_counts = {\n",
        "        'COVID': {'total': 3616, 'train': 2532, 'val': 542, 'test': 542},\n",
        "        'Viral_Pneumonia': {'total': 1345, 'train': 943, 'val': 201, 'test': 201},\n",
        "        'Normal': {'total': 10192, 'train': 7136, 'val': 1528, 'test': 1528}\n",
        "    }\n",
        "    actual_counts = {\n",
        "        'COVID': {'train_images': 0, 'train_masks': 0,\n",
        "                  'val_images': 0, 'val_masks': 0,\n",
        "                  'test_images': 0, 'test_masks': 0},\n",
        "        'Viral_Pneumonia': {'train_images': 0, 'train_masks': 0,\n",
        "                           'val_images': 0, 'val_masks': 0,\n",
        "                           'test_images': 0, 'test_masks': 0},\n",
        "        'Normal': {'train_images': 0, 'train_masks': 0,\n",
        "                  'val_images': 0, 'val_masks': 0,\n",
        "                  'test_images': 0, 'test_masks': 0}\n",
        "    }\n",
        "    for split in ['train', 'val', 'test']:\n",
        "        split_path = os.path.join(base_path, split)\n",
        "        if not os.path.exists(split_path):\n",
        "            print(f\"Warning: Split directory '{split_path}' does not exist.\")\n",
        "            continue\n",
        "\n",
        "        for class_name in class_names:\n",
        "            class_path = os.path.join(split_path, class_name)\n",
        "            if not os.path.exists(class_path):\n",
        "                print(f\"Warning: Class directory '{class_path}' does not exist.\")\n",
        "                continue\n",
        "\n",
        "            images_path = os.path.join(class_path, 'images')\n",
        "            masks_path = os.path.join(class_path, 'masks')\n",
        "\n",
        "            if os.path.exists(images_path):\n",
        "                actual_counts[class_name][f'{split}_images'] = count_files(images_path)\n",
        "            else:\n",
        "                print(f\"Warning: Images directory '{images_path}' does not exist.\")\n",
        "\n",
        "            if os.path.exists(masks_path):\n",
        "                actual_counts[class_name][f'{split}_masks'] = count_files(masks_path)\n",
        "            else:\n",
        "                print(f\"Warning: Masks directory '{masks_path}' does not exist.\")\n",
        "    results = []\n",
        "\n",
        "    for class_name, counts in actual_counts.items():\n",
        "        train_images = counts['train_images']\n",
        "        val_images = counts['val_images']\n",
        "        test_images = counts['test_images']\n",
        "        total_images = train_images + val_images + test_images\n",
        "\n",
        "        train_masks = counts['train_masks']\n",
        "        val_masks = counts['val_masks']\n",
        "        test_masks = counts['test_masks']\n",
        "        total_masks = train_masks + val_masks + test_masks\n",
        "\n",
        "        expected = expected_counts[class_name]\n",
        "        images_match = (\n",
        "            train_images == expected['train'] and\n",
        "            val_images == expected['val'] and\n",
        "            test_images == expected['test'] and\n",
        "            total_images == expected['total']\n",
        "        )\n",
        "        masks_match_images = (\n",
        "            train_masks == train_images and\n",
        "            val_masks == val_images and\n",
        "            test_masks == test_images and\n",
        "            total_masks == total_images\n",
        "        )\n",
        "        train_pct = round(train_images / total_images * 100, 1) if total_images > 0 else 0\n",
        "        val_pct = round(val_images / total_images * 100, 1) if total_images > 0 else 0\n",
        "        test_pct = round(test_images / total_images * 100, 1) if total_images > 0 else 0\n",
        "        results.append({\n",
        "            'Class': class_name,\n",
        "            'Train Images': train_images,\n",
        "            'Val Images': val_images,\n",
        "            'Test Images': test_images,\n",
        "            'Total Images': total_images,\n",
        "            'Train %': train_pct,\n",
        "            'Val %': val_pct,\n",
        "            'Test %': test_pct,\n",
        "            'Train Masks': train_masks,\n",
        "            'Val Masks': val_masks,\n",
        "            'Test Masks': test_masks,\n",
        "            'Total Masks': total_masks,\n",
        "            'Expected Train': expected['train'],\n",
        "            'Expected Val': expected['val'],\n",
        "            'Expected Test': expected['test'],\n",
        "            'Expected Total': expected['total'],\n",
        "            'Images Match Expected': images_match,\n",
        "            'Masks Match Images': masks_match_images\n",
        "        })\n",
        "    df = pd.DataFrame(results)\n",
        "    print(\"\\n=== Dataset Split Validation Results ===\\n\")\n",
        "    print(df[['Class', 'Train Images', 'Train %', 'Val Images', 'Val %', 'Test Images', 'Test %', 'Total Images',\n",
        "              'Images Match Expected', 'Masks Match Images']])\n",
        "    mismatches = df[~df['Images Match Expected'] | ~df['Masks Match Images']]\n",
        "    if not mismatches.empty:\n",
        "        print(\"\\n=== Detailed Analysis for Mismatches ===\\n\")\n",
        "        for _, row in mismatches.iterrows():\n",
        "            class_name = row['Class']\n",
        "            print(f\"Class: {class_name}\")\n",
        "\n",
        "            if not row['Images Match Expected']:\n",
        "                print(\"  Image count mismatch:\")\n",
        "                print(f\"    Train: {row['Train Images']} (Expected: {row['Expected Train']})\")\n",
        "                print(f\"    Val: {row['Val Images']} (Expected: {row['Expected Val']})\")\n",
        "                print(f\"    Test: {row['Test Images']} (Expected: {row['Expected Test']})\")\n",
        "                print(f\"    Total: {row['Total Images']} (Expected: {row['Expected Total']})\")\n",
        "\n",
        "            if not row['Masks Match Images']:\n",
        "                print(\"  Mask-Image count mismatch:\")\n",
        "                print(f\"    Train: {row['Train Masks']} masks vs {row['Train Images']} images\")\n",
        "                print(f\"    Val: {row['Val Masks']} masks vs {row['Val Images']} images\")\n",
        "                print(f\"    Test: {row['Test Masks']} masks vs {row['Test Images']} images\")\n",
        "                print(f\"    Total: {row['Total Masks']} masks vs {row['Total Images']} images\")\n",
        "            print()\n",
        "    else:\n",
        "        print(\"\\nAll classes have correct splits and matching masks/images counts! ✓\")\n",
        "    overall_correct_split = True\n",
        "    for _, row in df.iterrows():\n",
        "        # if new split method (as 10/10/80) should change here also:\n",
        "        if abs(row['Train %'] - 70) > 1 or abs(row['Val %'] - 15) > 1 or abs(row['Test %'] - 15) > 1:\n",
        "            overall_correct_split = False\n",
        "    if overall_correct_split:\n",
        "        print(\"\\nSplit Correctly!\")\n",
        "    else:\n",
        "        print(\"\\nWarning: The distribution doesn't match the expected distribution!!!\")\n",
        "    return df"
      ],
      "metadata": {
        "id": "o5p4M8mPZ-dB",
        "collapsed": true
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = validate_split(splitted_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfHFIjopr-9z",
        "outputId": "8469b0cf-5626-4b1a-8fb1-1338bba89dde"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Dataset Split Validation Results ===\n",
            "\n",
            "             Class  Train Images  Train %  Val Images  Val %  Test Images  \\\n",
            "0            COVID          2532     70.0         542   15.0          542   \n",
            "1  Viral_Pneumonia           943     70.1         201   14.9          201   \n",
            "2           Normal          7136     70.0        1528   15.0         1528   \n",
            "\n",
            "   Test %  Total Images  Images Match Expected  Masks Match Images  \n",
            "0    15.0          3616                   True                True  \n",
            "1    14.9          1345                   True                True  \n",
            "2    15.0         10192                   True                True  \n",
            "\n",
            "All classes have correct splits and matching masks/images counts! ✓\n",
            "\n",
            "Split Correctly!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "load data and apply data pre-processing steps on it."
      ],
      "metadata": {
        "id": "Poj0SEkvLC5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "class_types = ['train', 'val', 'test']\n",
        "def data_pre_processing(img_path, mask_path):\n",
        "    try:\n",
        "        # Normalization Config from ImageNet based models\n",
        "        # original resoulution is 299 x 299\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize((128, 128)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean, std)\n",
        "        ])\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        mask = Image.open(mask_path).convert('L')\n",
        "        img_tensor = transform(img)\n",
        "        mask = mask.resize((128, 128), Image.NEAREST)\n",
        "        mask_temsor = TF.to_tensor(mask)\n",
        "        mask_temsor = (mask_temsor > 0.5).float()\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {img_path} and {mask_path}: {e}\")\n",
        "        return None, None\n",
        "    return img_tensor, mask_temsor"
      ],
      "metadata": {
        "id": "aP4a5tiKYlkg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from enum import unique\n",
        "class_map = {'COVID': 0, 'Viral_Pneumonia': 1, 'Normal': 2}\n",
        "dataloaders = {}\n",
        "# only shuffle the training set\n",
        "for class_l in class_types:\n",
        "    images = []\n",
        "    masks = []\n",
        "    labels = []\n",
        "    cur_class_path = os.path.join(target_dir, class_l)\n",
        "    if not os.path.exists(cur_class_path):\n",
        "        print(f\"Warning! {cur_class_path} does not exists!\")\n",
        "        break\n",
        "    else:\n",
        "        print(cur_class_path)\n",
        "        for class_name in class_map.keys():\n",
        "            class_dir = os.path.join(cur_class_path, class_name)\n",
        "            if not os.path.exists(class_dir):\n",
        "                print(f\"Warning! {class_dir} does not exists!\")\n",
        "                break\n",
        "            else:\n",
        "                image_dir = os.path.join(class_dir, 'images')\n",
        "                mask_dir = os.path.join(class_dir, 'masks')\n",
        "                if not os.path.exists(image_dir) or not os.path.exists(mask_dir):\n",
        "                    print(f\"Warning! {image_dir} or {mask_dir} does not exists!\")\n",
        "                    break\n",
        "                else:\n",
        "                    image_files = glob.glob(os.path.join(image_dir, '*'))\n",
        "                    # Reduce the dataset size to 1/10 since training time too long\n",
        "                    random.seed(42)\n",
        "                    subset_size = max(len(image_files) // 10, 1)\n",
        "                    sampled_image_files = random.sample(image_files, subset_size)\n",
        "                    print(f\"Sampling {subset_size}/{len(image_files)} images from {class_name} in {class_l}\")\n",
        "                    for img_path in sampled_image_files:\n",
        "                        # get the correspounding mask file\n",
        "                        # the mask and the correspounding original image has the same name\n",
        "                        img_filename = os.path.basename(img_path)\n",
        "                        mask_path = os.path.join(mask_dir, img_filename)\n",
        "                        if os.path.exists(mask_path):\n",
        "                            img_tensor, mask_tensor = data_pre_processing(img_path, mask_path)\n",
        "                            if img_tensor is not None and mask_tensor is not None:  # Changed from or to and\n",
        "                                images.append(img_tensor)\n",
        "                                masks.append(mask_tensor)\n",
        "                                labels.append(class_map[class_name])\n",
        "\n",
        "        if images:\n",
        "            print(f\"{class_l} loaded {len(images)} samples\")\n",
        "            images_tensor = torch.stack(images)\n",
        "            masks_tensor = torch.stack(masks)\n",
        "            labels_tensor = torch.tensor(labels)\n",
        "            # check distribution\n",
        "            unique_labels, counts = torch.unique(labels_tensor, return_counts=True)\n",
        "            distribution = {list(class_map.keys())[l.item()]: c.item() for l, c in zip(unique_labels, counts)}\n",
        "            print(f\"Class distribution in {class_l}: {distribution}\")\n",
        "            dataset = TensorDataset(images_tensor, masks_tensor, labels_tensor)\n",
        "            shuffle = (class_l == 'train')\n",
        "            dataloaders[class_l] = DataLoader(dataset, batch_size=16, shuffle=shuffle)\n",
        "        else:\n",
        "            print(f\"No images found in {class_l}, please check code + data folder again\")\n",
        "            break"
      ],
      "metadata": {
        "id": "T5xAdWiYLHFF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "502ba7d4-9c1c-4cdb-eeb4-2c2f27f7010c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Projects/datasets/COVID-19_Radiography_Dataset/Splitted_database/train\n",
            "Sampling 253/2532 images from COVID in train\n",
            "Sampling 94/943 images from Viral_Pneumonia in train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show a batch of the sample."
      ],
      "metadata": {
        "id": "80Qc3P6-OKRc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataloaders)\n",
        "images, masks, labels = next(iter(dataloaders['train']))\n",
        "mean = torch.tensor(mean).view(1, 3, 1, 1)\n",
        "std = torch.tensor(std).view(1, 3, 1, 1)\n",
        "images_display = (images * std) + mean\n",
        "images_display = images_display.clamp(0, 1)\n",
        "fig, axes = plt.subplots(4, 3, figsize=(12, 10))\n",
        "# only display first four\n",
        "for i in range(4):\n",
        "    img = images_display[i].permute(1, 2, 0).cpu().numpy()\n",
        "    axes[i, 0].imshow(img)\n",
        "    axes[i, 0].set_title(f'Image {i+1}, Class: {list(class_map.keys())[labels[i]]}')\n",
        "    axes[i, 0].axis('off')\n",
        "    # Squeeze the mask tensor to remove the single-dimension at the beginning\n",
        "    mask_np = masks[i].squeeze().cpu().numpy()\n",
        "    axes[i, 1].imshow(mask_np, cmap='gray')\n",
        "    axes[i, 1].set_title(f'Mask {i+1}')\n",
        "    axes[i, 1].axis('off')\n",
        "    overlay = img.copy()\n",
        "    # show mask as a red overlay layer\n",
        "    for c in range(3):\n",
        "        channel_overlay = overlay[:, :, c].copy()\n",
        "        if c == 0:\n",
        "            channel_overlay[mask_np > 0.5] = 1.0\n",
        "        else:\n",
        "            channel_overlay[mask_np > 0.5] = 0.5\n",
        "        overlay[:, :, c] = channel_overlay\n",
        "    alpha = 0.3\n",
        "    blended = (1-alpha) * img + alpha * overlay\n",
        "    axes[i, 2].imshow(blended)\n",
        "    axes[i, 2].set_title(f'Blended {i+1}')\n",
        "    axes[i, 2].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_Z1JxiHY2P8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create the model"
      ],
      "metadata": {
        "id": "AC0o3tFi3rVp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss function Combination."
      ],
      "metadata": {
        "id": "XcMSNxSXSXI0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loss weight should be [seg_weight:cls_weight] to define which event is more important\n",
        "def loss_function(seg_pred, cls_pred, seg_true, cls_true, loss_weight):\n",
        "    seg_criterion = nn.BCELoss()\n",
        "    cls_criterion = nn.CrossEntropyLoss()\n",
        "    seg_loss = seg_criterion(seg_pred, seg_true)\n",
        "    cls_loss = cls_criterion(cls_pred, cls_true)\n",
        "    total_loss = seg_loss * loss_weight[0] + cls_loss * loss_weight[1]\n",
        "    return total_loss, seg_loss, cls_loss"
      ],
      "metadata": {
        "id": "TLFG--e4SWV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_combined_model(num_classes):\n",
        "    unet_model = smp.Unet(\n",
        "        encoder_name=\"resnet18\",\n",
        "        encoder_weights=\"imagenet\",\n",
        "        in_channels=3,\n",
        "        classes=1,\n",
        "        activation=\"sigmoid\"\n",
        "    )\n",
        "    resnet18_model = torchvision.models.resnet18(pretrained=True)\n",
        "    original_conv = resnet18_model.conv1\n",
        "    resnet18_model.conv1 = nn.Conv2d(\n",
        "        4,\n",
        "        original_conv.out_channels,\n",
        "        kernel_size=original_conv.kernel_size,\n",
        "        stride=original_conv.stride,\n",
        "        padding=original_conv.padding,\n",
        "        bias=original_conv.bias\n",
        "    )\n",
        "    with torch.no_grad():\n",
        "        resnet18_model.conv1.weight[:, :3] = original_conv.weight\n",
        "    num_ftrs = resnet18_model.fc.in_features\n",
        "    resnet18_model.fc = nn.Linear(num_ftrs, num_classes)\n",
        "    # foward propagation function\n",
        "    # x is an input image tensor\n",
        "    def foward_pf(x):\n",
        "        mask = unet_model(x)\n",
        "        x_combine = torch.cat((x, mask), dim=1)\n",
        "        classification = resnet18_model(x_combine)\n",
        "        return mask, classification\n",
        "    return foward_pf, (unet_model, resnet18_model)"
      ],
      "metadata": {
        "id": "g66GzPXM6f_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the Model"
      ],
      "metadata": {
        "id": "GgB864sTYUAd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# scheduler: to adjust the study rate\n",
        "# patience: for early stopping\n",
        "def train_model(foward_pf, models, dataloaders, optimizer, loss_weight, scheduler=None, num_epochs=25, patience=5):\n",
        "    # preparation stage\n",
        "    seg_model, classify_model = models\n",
        "    seg_model = seg_model.to(device)\n",
        "    classify_model = classify_model.to(device)\n",
        "    best_seg_state = copy.deepcopy(seg_model.state_dict())\n",
        "    best_cls_state = copy.deepcopy(classify_model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    best_epoch = 0\n",
        "    history = {\n",
        "        'train_loss': [], 'val_loss': [],\n",
        "        'train_seg_loss': [], 'val_seg_loss': [],\n",
        "        'train_cls_loss': [], 'val_cls_loss': [],\n",
        "        'train_acc': [], 'val_acc': []\n",
        "    }\n",
        "    counter = 0\n",
        "    # training stage\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "        print('-' * 10)\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                seg_model.train()\n",
        "                classify_model.train()\n",
        "            else:\n",
        "                seg_model.eval()\n",
        "                classify_model.eval()\n",
        "            running_loss = 0.0\n",
        "            running_seg_loss = 0.0\n",
        "            running_cls_loss = 0.0\n",
        "            running_corrects = 0\n",
        "            for inputs, masks, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                masks = masks.to(device)\n",
        "                labels = labels.to(device)\n",
        "                optimizer.zero_grad()\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    mask_preds, class_preds = foward_pf(inputs)\n",
        "                    loss, seg_loss, cls_loss = loss_function(mask_preds, class_preds, masks, labels, loss_weight)\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_seg_loss += seg_loss.item() * inputs.size(0)\n",
        "                running_cls_loss += cls_loss.item() * inputs.size(0)\n",
        "                _, preds = torch.max(class_preds, 1)\n",
        "                running_corrects += torch.sum(preds==labels.data)\n",
        "                # update learning rate\n",
        "                if scheduler is not None and phase == 'train':\n",
        "                    scheduler.step()\n",
        "                dataset_size = len(dataloaders[phase].dataset)\n",
        "                epoch_loss = running_loss / dataset_size\n",
        "                epoch_seg_loss = running_seg_loss / dataset_size\n",
        "                epoch_cls_loss = running_cls_loss / dataset_size\n",
        "                epoch_acc = running_corrects.double() / dataset_size\n",
        "                history[f'{phase}_loss'].append(epoch_loss)\n",
        "                history[f'{phase}_seg_loss'].append(epoch_seg_loss)\n",
        "                history[f'{phase}_cls_loss'].append(epoch_cls_loss)\n",
        "                history[f'{phase}_acc'].append(epoch_acc.item())\n",
        "                print(f'{phase} Loss: {epoch_loss:.4f} Seg Loss: {epoch_seg_loss:.4f} Cls Loss: {epoch_cls_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "                # deep copy the model\n",
        "                if phase == 'val' and epoch_acc > best_acc:\n",
        "                    best_acc = epoch_acc\n",
        "                    best_epoch = epoch\n",
        "                    best_seg_state = copy.deepcopy(seg_model.state_dict())\n",
        "                    best_cls_state = copy.deepcopy(classify_model.state_dict())\n",
        "                    counter = 0\n",
        "                elif phase == 'val':\n",
        "                    counter += 1\n",
        "\n",
        "                if counter >= patience:\n",
        "                    print(f'Early stopping at epoch {epoch}')\n",
        "                    break\n",
        "        print(f'Best validation accuracy: {best_acc:.4f} at epoch {best_epoch}')\n",
        "        return (best_seg_state, best_cls_state), history\n"
      ],
      "metadata": {
        "id": "1xZR79y-YmBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization"
      ],
      "metadata": {
        "id": "Ht9Af3kk5ZGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_training_history(history):\n",
        "    fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n",
        "    epochs = range(1, len(history['train_loss']) + 1)\n",
        "    # total loss\n",
        "    axs[0, 0].plot(epochs, history['train_loss'], 'b-', label='Train Loss')\n",
        "    axs[0, 0].plot(epochs, history['val_loss'], 'r-', label='Validation Loss')\n",
        "    axs[0, 0].set_xlabel('Epochs')\n",
        "    axs[0, 0].set_ylabel('Loss')\n",
        "    axs[0, 0].set_title('Total Loss')\n",
        "    axs[0, 0].legend()\n",
        "    # segmentation loss\n",
        "    axs[0, 1].plot(epochs, history['train_seg_loss'], 'b-', label='Train Seg Loss')\n",
        "    axs[0, 1].plot(epochs, history['val_seg_loss'], 'r-', label='Validation Seg Loss')\n",
        "    axs[0, 1].set_xlabel('Epochs')\n",
        "    axs[0, 1].set_ylabel('Loss')\n",
        "    axs[0, 1].set_title('Segmentation Loss')\n",
        "    axs[0, 1].legend()\n",
        "    # classification loss\n",
        "    axs[1, 0].plot(epochs, history['train_cls_loss'], 'b-', label='Train Cls Loss')\n",
        "    axs[1, 0].plot(epochs, history['val_cls_loss'], 'r-', label='Validation Cls Loss')\n",
        "    axs[1, 0].set_xlabel('Epochs')\n",
        "    axs[1, 0].set_ylabel('Loss')\n",
        "    axs[1, 0].set_title('Classification Loss')\n",
        "    axs[1, 0].legend()\n",
        "    # Accuracy\n",
        "    axs[1, 1].plot(epochs, history['train_acc'], 'b-', label='Train Accuracy')\n",
        "    axs[1, 1].plot(epochs, history['val_acc'], 'r-', label='Validation Accuracy')\n",
        "    axs[1, 1].set_xlabel('Epochs')\n",
        "    axs[1, 1].set_ylabel('Accuracy')\n",
        "    axs[1, 1].set_title('Accuracy')\n",
        "    axs[1, 1].legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_predictions(foward_pf, models, num_samples=6):\n",
        "    seg_model, classify_model = models\n",
        "    test_loader = dataloaders['test']\n",
        "    seg_model.eval()\n",
        "    classify_model.eval()\n",
        "    inputs, masks, labels = next(iter(test_loader))\n",
        "    inputs = inputs.to(device)\n",
        "    masks = masks.to(device)\n",
        "    labels = labels.to(device)\n",
        "    with torch.no_grad():\n",
        "        mask_preds, outputs = foward_pf(inputs.to(device))\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "    inputs_display = (inputs * std) + mean\n",
        "    images_np = inputs_display.permute(0, 2, 3, 1).cpu().numpy()\n",
        "    masks_np = masks.cpu().numpy()\n",
        "    mask_preds_np = mask_preds.cpu().numpy()\n",
        "    fig, axes = plt.subplots(num_samples, 3, figsize=(15, 25))\n",
        "    for i in range(num_samples):\n",
        "        axes[i, 0].imshow(images_np[i])\n",
        "        axes[i, 0].set_title(f'Groud Truth Image {class_names[labels[i]]}')\n",
        "        axes[i, 0].axis('off')\n",
        "        axes[i, 1].imshow(masks_np[i][0], cmap='gray')\n",
        "        axes[i, 1].set_title(f'Ground Truth Mask {class_names[labels[i]]}')\n",
        "        axes[i, 1].axis('off')\n",
        "        axes[i, 2].imshow(mask_preds_np[i][0], cmap='gray')\n",
        "        axes[i, 2].set_title(f'Predicted Mask {class_names[preds[i]]}')\n",
        "        axes[i, 2].axis('off')\n",
        "        color = 'green' if preds[i] == labels[i] else 'red'\n",
        "        for j in range(3):\n",
        "            axes[i, j].spines['bottom'].set_color(color)\n",
        "            axes[i, j].spines['top'].set_color(color)\n",
        "            axes[i, j].spines['left'].set_color(color)\n",
        "            axes[i, j].spines['right'].set_color(color)\n",
        "            axes[i, j].spines['bottom'].set_linewidth(5)\n",
        "            axes[i, j].spines['top'].set_linewidth(5)\n",
        "            axes[i, j].spines['left'].set_linewidth(5)\n",
        "            axes[i, j].spines['right'].set_linewidth(5)\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "w5VI6urD5Y4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation\n",
        "Involve a part of the visualization."
      ],
      "metadata": {
        "id": "5sVEWqoJwrSj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(forward_pf, models):\n",
        "    test_loader = dataloaders['test']\n",
        "    seg_model, classify_model = models\n",
        "    seg_model.eval()\n",
        "    classify_model.eval()\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    # test without gradient tracking\n",
        "    with torch.no_grad():\n",
        "        for inputs, masks, labels in test_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            masks = masks.to(device)\n",
        "            labels = labels.to(device)\n",
        "            _, outputs = forward_pf(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            y_true.extend(labels.cpu().numpy())\n",
        "            y_pred.extend(preds.cpu().numpy())\n",
        "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "    class_report = classification_report(y_true, y_pred)\n",
        "    print(\"Classification Report:\")\n",
        "    print(class_report)\n",
        "    # Confusion matrix\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n",
        "    # Accuracy\n",
        "    accuracy = np.sum(np.array(y_true) == np.array(y_pred)) / len(y_true)\n",
        "    print(f\"Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "O2EeJFarwtEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Os7ezmqf7m91"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Execution"
      ],
      "metadata": {
        "id": "lf-jFi9eRhix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "foward_pf, models = create_combined_model(num_classes=3)\n",
        "segmentation_model, classification_model = models\n",
        "params = list(segmentation_model.parameters()) + list(classification_model.parameters())\n",
        "optimizer = optim.Adam(params, lr=0.001)\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "for split, loader in dataloaders.items():\n",
        "    print(f\"{split}: {len(dataloaders.items())} samples\")\n",
        "print('Start Training...')\n",
        "start_time = time.time()\n",
        "best_states, history = train_model(\n",
        "    foward_pf,\n",
        "    models,\n",
        "    dataloaders={k: v for k, v in dataloaders.items() if k in ['train', 'val']},\n",
        "    optimizer = optimizer,\n",
        "    loss_weight=[0.3, 0.7],\n",
        "    scheduler=scheduler,\n",
        "    num_epochs=25,\n",
        "    patience=7\n",
        ")\n",
        "time_elapsed = time.time() - start_time\n",
        "print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "plot_training_history(history)\n",
        "best_seg_state, best_cls_state = best_states\n",
        "segmentation_model.load_state_dict(best_seg_state)\n",
        "classification_model.load_state_dict(best_cls_state)\n",
        "torch.save(best_seg_state, 'best_seg_state.pth')\n",
        "torch.save(best_cls_state, 'best_cls_state.pth')\n",
        "evaluate_model(foward_pf, models)\n",
        "plot_predictions(foward_pf, models)"
      ],
      "metadata": {
        "id": "t7-bVXAzRj2c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}